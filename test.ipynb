{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:01:28.447182Z",
     "start_time": "2025-05-15T09:01:23.365848Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Failed to load image Python extension.*\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from CustomTextStreamer import CustomTextStreamer, generate_stream\n",
    "\n",
    "Q_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"../dl_models/Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # quantization_config=Q_config,\n",
    "    # attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "model = model.to_bettertransformer()\n",
    "model.to(device)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "initial_messages = []\n",
    "messages = initial_messages.copy()\n",
    "enable_thinking = True\n",
    "skip_prompt=True\n",
    "skip_special_tokens=True\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \").strip()\n",
    "    if user_input.lower() == \"/exit\":\n",
    "        print(\"Exiting chat.\")\n",
    "        break\n",
    "    if user_input.lower() == \"/clear\":\n",
    "        messages = initial_messages.copy()\n",
    "        print(\"Chat history cleared. Starting a new conversation.\")\n",
    "        continue\n",
    "    if user_input.lower() == \"/no_think\":\n",
    "        if enable_thinking:\n",
    "            enable_thinking = False\n",
    "            print(\"Thinking = False.\")\n",
    "        else:\n",
    "            enable_thinking = True\n",
    "            print(\"Thinking = True.\")\n",
    "        continue\n",
    "    if user_input.lower() == \"/skip_prompt\":\n",
    "        if skip_prompt:\n",
    "            skip_prompt = False\n",
    "            print(\"skip_prompt = False.\")\n",
    "        else:\n",
    "            skip_prompt = True\n",
    "            print(\"skip_prompt = True.\")\n",
    "        continue\n",
    "    if user_input.lower() == \"/skip_special_tokens\":\n",
    "        if skip_special_tokens:\n",
    "            skip_special_tokens = False\n",
    "            print(\"skip_special_tokens = False.\")\n",
    "        else:\n",
    "            skip_special_tokens = True\n",
    "            print(\"skip_special_tokens = True.\")\n",
    "        continue\n",
    "    if not user_input:\n",
    "        print(\"Input cannot be empty. Please enter something.\")\n",
    "        continue\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response, stop_flag = generate_stream(model, tokenizer, messages, enable_thinking, skip_prompt, skip_special_tokens, 8192)\n",
    "    print(\"\", flush=True)\n",
    "    if stop_flag:\n",
    "        continue\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response})"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:496: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.qwen3.modeling_qwen3 because of the following error (look up to see its traceback):\nDLL load failed while importing flash_attn_2_cuda: 找不到指定的程序。",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001B[0m in \u001B[0;36m_get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1966\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1967\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\".\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmodule_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1968\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\__init__.py\u001B[0m in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    126\u001B[0m             \u001B[0mlevel\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 127\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_bootstrap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gcd_import\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpackage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    128\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\models\\qwen3\\modeling_qwen3.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0mmodeling_attn_mask_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mAttentionMaskConverter\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m...\u001B[0m\u001B[0mmodeling_flash_attention_utils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFlashAttentionKwargs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m from ...modeling_outputs import (\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\modeling_flash_attention_utils.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mis_flash_attn_2_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m     \u001B[1;32mfrom\u001B[0m \u001B[0mflash_attn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbert_padding\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mindex_first_axis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpad_input\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0munpad_input\u001B[0m  \u001B[1;31m# noqa\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     37\u001B[0m     \u001B[1;32mfrom\u001B[0m \u001B[0mflash_attn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mflash_attn_func\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflash_attn_varlen_func\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\flash_attn\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m from flash_attn.flash_attn_interface import (\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[0mflash_attn_func\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\flash_attn\\flash_attn_interface.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m     \u001B[1;32mimport\u001B[0m \u001B[0mflash_attn_2_cuda\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mflash_attn_gpu\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing flash_attn_2_cuda: 找不到指定的程序。",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11236\\1368199366.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mmodel_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"../dl_models/Qwen3-1.7B\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mAutoTokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m model = AutoModelForCausalLM.from_pretrained(\n\u001B[0m\u001B[0;32m     20\u001B[0m     \u001B[0mmodel_name\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;31m# quantization_config=Q_config,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001B[0m in \u001B[0;36mfrom_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    566\u001B[0m             )\n\u001B[0;32m    567\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_model_mapping\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 568\u001B[1;33m             \u001B[0mmodel_class\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_model_class\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_model_mapping\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    569\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mmodel_class\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig_class\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msub_configs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"text_config\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    570\u001B[0m                 \u001B[0mconfig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_text_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001B[0m in \u001B[0;36m_get_model_class\u001B[1;34m(config, model_mapping)\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0m_get_model_class\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_mapping\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 388\u001B[1;33m     \u001B[0msupported_models\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_mapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    389\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msupported_models\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    390\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0msupported_models\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    768\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmodel_type\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_model_mapping\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    769\u001B[0m             \u001B[0mmodel_name\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_model_mapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodel_type\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 770\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_load_attr_from_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    771\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    772\u001B[0m         \u001B[1;31m# Maybe there was several model types associated with this config.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001B[0m in \u001B[0;36m_load_attr_from_module\u001B[1;34m(self, model_type, attr)\u001B[0m\n\u001B[0;32m    782\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmodule_name\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_modules\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    783\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_modules\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodule_name\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\".{module_name}\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"transformers.models\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 784\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mgetattribute_from_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_modules\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mmodule_name\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    785\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    786\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001B[0m in \u001B[0;36mgetattribute_from_module\u001B[1;34m(module, attr)\u001B[0m\n\u001B[0;32m    698\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mattr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    699\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgetattribute_from_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mattr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 700\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    701\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mattr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    702\u001B[0m     \u001B[1;31m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1953\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPlaceholder\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1954\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_class_to_module\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1955\u001B[1;33m             \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_class_to_module\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1956\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1957\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_modules\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\anaconda3\\lib\\site-packages\\transformers\\utils\\import_utils.py\u001B[0m in \u001B[0;36m_get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1967\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\".\"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mmodule_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1968\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1969\u001B[1;33m             raise RuntimeError(\n\u001B[0m\u001B[0;32m   1970\u001B[0m                 \u001B[1;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1971\u001B[0m                 \u001B[1;34mf\" traceback):\\n{e}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.models.qwen3.modeling_qwen3 because of the following error (look up to see its traceback):\nDLL load failed while importing flash_attn_2_cuda: 找不到指定的程序。"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "57d68194cf590d1f"
  },
  {
   "cell_type": "code",
   "id": "376ef342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T09:01:20.006638Z",
     "start_time": "2025-05-15T09:01:19.995693Z"
    }
   },
   "source": [
    "exit(0)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9a1bd7fd",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40814eaa",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
